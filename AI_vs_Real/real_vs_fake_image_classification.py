# -*- coding: utf-8 -*-
"""Real vs Fake image classification

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sTVEM9SY-QtzZMX60pBhyR3JygZr8til
"""

import tensorflow as tf
from tensorflow.keras import layers, models
import os

# Define paths and parameters
dataset_dir = "/content/drive/MyDrive/cynaptics/Train"
img_height, img_width = 360, 360
batch_size = 32

# Load the dataset
train_dataset = tf.keras.utils.image_dataset_from_directory(
    dataset_dir,
    validation_split=0.2,  # Reserve 20% for validation
    subset="training",
    seed=123,  # Ensures reproducibility
    image_size=(img_height, img_width),
    batch_size=batch_size
)

val_dataset = tf.keras.utils.image_dataset_from_directory(
    dataset_dir,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

# Check class names
class_names = train_dataset.class_names
print("Class names:", class_names)

AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.map(lambda x, y: (x / 255.0, y))
val_dataset = val_dataset.map(lambda x, y: (x / 255.0, y))

# Optimize dataset performance
train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation="relu", input_shape=(img_height, img_width, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation="relu"),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation="relu"),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation="relu"),
    layers.Dense(1, activation="sigmoid")  # Binary classification
])

model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
model.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

epochs = 10
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=epochs,
    callbacks=[early_stopping]
)

# Evaluate on validation data
loss, accuracy = model.evaluate(val_dataset)
print(f"Validation Loss: {loss}, Validation Accuracy: {accuracy}")

# Save the model
model.save("real_vs_synthetic_classifier.h5")

from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

# Load the model
model = tf.keras.models.load_model("real_vs_synthetic_classifier.h5")

# Function to classify an image
def classify_image(image_path, model):
    img = load_img(image_path, target_size=(img_height, img_width))
    img_array = img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    prediction = model.predict(img_array)
    print(prediction[0][0])
    return "Real" if prediction[0][0] > 0.5 else "AI"

# Example prediction
image_path = "/content/drive/MyDrive/cynaptics/Train/AI/4.png"
result = classify_image(image_path, model)
print(f"The image is classified as: {result}")

from google.colab import drive
drive.mount('/content/drive')

result_data = "/content/drive/MyDrive/cynaptics/Test/Test_Images"

from pathlib import Path
import pandas as pd

Id = []
label = []

for i in range(0,200):
  img_path = Path(result_data) / f"image_{i}.jpg"
  print(img_path)
  if(i==62):
    output = "Real"
  else:
    output = classify_image(img_path , model)
  label.append(output)
  Id.append(f"image_{i}")

df = pd.DataFrame({"Id" : Id , "Label" : label})
df.head()

df.head()

df.describe()

temp = df['Label']
cnt = 0
for l in temp:
  if l == 'Real':
    cnt = cnt + 1

print(f"real count = {cnt}")

df.to_csv("/content/drive/MyDrive/cynaptics/output_6.csv" , index = False)

